{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panomaly\n",
    "\"Understanding the network of user interaction anomalies\"\n",
    "### A Consulting Project for [Lazy Lantern](https://www.lazylantern.com)\n",
    "\n",
    "## Donald W. Hoard, Ph.D.   \n",
    "Data Science Fellow    \n",
    "[Insight Data Science](https://insightfellows.com/data-science)   \n",
    "Los Angeles - Jan 2020\n",
    "\n",
    "An algorithm that uses a custom Hybrid Graph-Bayes model to identify linked anomalies in website/app user interactions. I built Panomaly in just 3 weeks during early January 2020 as a project for my [Insight Data Science](https://insightfellows.com/data-science).\n",
    "\n",
    "Panomaly is intended as an add-on to [Lazy Lantern's](https://www.lazylantern.com) existing anomaly detection algorithm.\n",
    "Panomaly is fully integrated with the raw event and processed anomaly databases, and can be quickly run at the end of every hour (following anomaly detection for that hour) to surface linked anomalies.\n",
    "Panomaly produces a table of linked anomalies containing a single evaluation metric (Qpan) along with a verdict (True or False) indicating whether or not to surface the linkage to the client dashboard.\n",
    "The verdict function (as well as the calculation of Qpan) can be easily modified as desired (or even set up to produce different results on an app-by-app basis).\n",
    "\n",
    "### Nomenclature\n",
    "\n",
    "* **event** = a single (raw) user action\n",
    "\n",
    "* **metric** = a time series of the same event aggregated over all users\n",
    "\n",
    "* **anomaly** = a metric flagged by the forecasting algorithm as outside the confidence interval for the current time interval\n",
    "\n",
    "### Output\n",
    "There are two dataframes created as output by Panomaly, which can be used as input to further code for surfacing the linked anomalies:\n",
    "\n",
    "* ```pan_la_df```: The Linked Anomalies dataframe contains information about linked pairs of anomalies, including the individual and combined metrics used to evaluate the relative \"strength\" or \"importance\" of their linkage. For example: \n",
    "\n",
    "| _ | N1 | id_anom1 | id_metric1 | metric_name1 | N2 | id_anom2 | id_metric2 | metric_name2 | PbProb | PbNab | PfProb | Gmod1 | Gdeg1 | Gbtw1 | Gevc1 | Gavg1 | Gmod2 | Gdeg2 | Gbtw2 | Gevc2 | Gavg2 | pan_class | Qp | Qg | Qpan | Qcrit | Verdict |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 79 | 19021 | 4473 | Side Nav Clicked | 79 | 19021 | 4473 | Side Nav Clicked | 0.067568 | 5 | 0.004850 | 0 | 0.397059 | 0.264518 | 0.343285 | 0.334954 | 0 | 0.397059 | 0.264518 | 0.343285 | 0.334954 | 4 | 0.067741 | 0.473697 | 0.478516 | 0.0 | True |\n",
    "| 1 | 79 | 19021 | 4473 | Side Nav Clicked | 149 | 19022 | 4470 | App Timing Metric | 0.158532 | 18 | 0.017459 | 0 | 0.397059 | 0.264518 | 0.343285 | 0.334954 | 2 | 0.514706 | 0.396241 | 0.462934 | 0.457960 | 2 | 0.159490 | -1.000000 | 0.105998 | 0.1 | True |\n",
    "| 2 | 149 | 19022 | 4470 | App Timing Metric | 73 | 19024 | 4471 | First Contentful Paint | 0.583351 | 48 | 0.046557 | 2 | 0.514706 | 0.396241 | 0.462934 | 0.457960 | 2 | 0.176471 | 0.016147 | 0.203546 | 0.132054 | 3 | 0.585206 | 0.476620 | 0.754740 | 0.1 | True |\n",
    "| 3 | 79 | 19021 | 4473 | Side Nav Clicked | 43 | 19023 | 4468 | First Paint | 0.000000 | 0 | 0.000000 | 0 | 0.397059 | 0.264518 | 0.343285 | 0.334954 | 2 | 0.147059 | 0.007143 | 0.191328 | 0.115177 | -1 | 0.000000 | 0.354203 | 0.000000 | 1.0 | False |\n",
    "| 4 | 43 | 19023 | 4468 | First Paint | 149 | 19022 | 4470 | App Timing Metric | 0.221624 | 17 | 0.016489 | 2 | 0.147059 | 0.007143 | 0.191328 | 0.115177 | 2 | 0.514706 | 0.396241 | 0.462934 | 0.457960 | 3 | 0.222237 | 0.472222 | 0.521903 | 0.1 | True |\n",
    "| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |\n",
    "\n",
    "\n",
    "* ```pan_master_report_df```: The Master Report dataframe contains a list of grouped anomalies in different classes (described below) that have received a True verdict (surface to client dashboard). For example:\n",
    "\n",
    "| _ | id_anom | id_metric | metric_name | pan_class | pan_class_tag |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| 0 | [19021] | [4473] | [Side Nav Clicked] | 4 | Pb & G (self) |\n",
    "| 1 | [19022] | [4470] | [App Timing Metric] | 4 | Pb & G (self) |\n",
    "| 3 | [19022, 19023, 19024] | [4470, 4468, 4471] | [App Timing Metric, First Paint, First Contentful Paint] | 3 | Pb & G |\n",
    "| 4 | [19021, 19022] | [4473, 4470] | [Side Nav Clicked, App Timing Metric] | 2 | Pb only |\n",
    "\n",
    "\n",
    "\n",
    "### About\n",
    "For reference, this code version is ```panomaly-v14.0-offline```. This is the offline demonstration version of Panomaly that uses a subset of anonymized sample data rather than connecting on-the-fly to [Lazy Lantern's](https://www.lazylantern.com) proprietary databases.\n",
    "\n",
    "\n",
    "### License\n",
    "Permission to view and try the demo version of this code for personal or educational use is granted; however, copyright (including rights to modify and/or distribute) are solely held by the author (D. W. Hoard), with an unlimited license granted to Lazy Lantern, in perpetuity, to use, modify, and/or distribute the code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Basic external inputs\n",
    "These are the necessary inputs that enable this code to define which subset of data to work on. They will have to be provided by the Python code that calls Panomaly.\n",
    "\n",
    "* **pan_org_id** = Organization ID number (from organization table in postgreSQL dB)\n",
    "* **pan_app_id** = Application ID number (from app table in postgreSQL DB)\n",
    "* **pan_tstart** = start time of current interval (see sample format below)\n",
    "* **pan_time_interval** = sampling window, in seconds (e.g., 3600 = 1 hour)\n",
    "\n",
    "Manually set inputs used for testing are included in the next cell.\n",
    "Change ```if True:``` to ```if False:``` to bypass the manual settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if False:\n",
    "if True:\n",
    "    pan_org_id = 3\n",
    "    pan_app_id = 33\n",
    "    \n",
    "    pan_time_start = '2020-01-11 03:00:00' # sample time interval with many (13) anomalies\n",
    "\n",
    "    # pan_time_interval is the 1 hour sampling window - this will generally not change\n",
    "    pan_time_interval = 3600 # seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Verbosity\n",
    "Set the verbosity of this code.\n",
    "\n",
    "```VERBOSE = False```: no diagnostic output (normal operation)    \n",
    "```VERBOSE = True```: display diagnostic output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VERBOSE = False\n",
    "VERBOSE = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Import general purpose packages used throughout the code\n",
    "Packages used for specific tasks are imported later, before the relevant code blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Functions for communicating with databases\n",
    "In the online version of Panomaly, the next cell defines functions used to interact with Lazy Lantern's databases. These have been removed to prevent access to Lazy Lantern's proprietary data. Instead, a subset of anonymized sample data will be used to demonstrate the functionality of Panomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Define other global functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a fractional probability (e.g., 0.15) to a \n",
    "# percentage (e.g., 15%) for pretty output.\n",
    "def pan_pp(fx):\n",
    "    return int(round((fx*100),0))\n",
    "\n",
    "\n",
    "# This is a function used to combine individual metrics \n",
    "# on the way to producing the final metric Qpan.\n",
    "# It is based on the geometric distance formula, and can \n",
    "# be thought of as defining a distance vector in the parameter \n",
    "# space of the two metrics being combined. It allows for some \n",
    "# combinations of x and y both being non-zero having a larger \n",
    "# \"weight\" than the case where one of x,y has the maximum value \n",
    "# and the other has the minimum value.\n",
    "def combine_scores(x,y):\n",
    "    return(np.sqrt(x**2 + y**2))\n",
    "\n",
    "\n",
    "# Normalizes a list to the maximum of the list.\n",
    "# Used during the calculation of Qpan.\n",
    "def normalize_to_max(xlist):\n",
    "    return (xlist)/np.max(xlist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## The Verdict Function\n",
    "This function evaluates the ```Qpan``` metric scores and returns a verdict (```True``` or ```False```) indicating whether the anomaly linkage should or should not be surfaced to the client dashboard, respectively. Several methods are encoded here; a particular method can be selected when the verdict function is called.\n",
    "\n",
    "* **limit10**: This is the method I am using right now. It is very basic, and delivers a ```True``` verdict for ```Qpan >= 0.10```. Nonetheless, it seems to do a good job of surfacing the anomaly links that my manual inspections of the results suggest as the reliable ones.   \n",
    "\n",
    "\n",
    "* **median**: This method compares the individual ```Qpan``` score to the median of all of the ```Qpan``` scores in a given ```pan_class``` (see ```pan_class``` designations below), and returns a verdict of True if ```Qpan >= median```.   \n",
    "\n",
    "\n",
    "* **median1050**: This is similar to the **median** method, but sets the critical threshold to a value of 0.10 or 0.50 if the median is less or more than those values, respectivelty.   \n",
    "\n",
    "\n",
    "* **mean**: Like the **median** method, but compares ```Qpan``` to the mean of all ```Qpan``` values in a ```pan_class```.   \n",
    "\n",
    "\n",
    "* **all**: Returns a verdict of ```True``` for all values of ```Qpan```. This is used for ```pan_class = 4``` (self-linkages).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pan_verdict_function(x, y, method):\n",
    "    if (method == 'limit10'): y_crit = 0.10\n",
    "        \n",
    "    if (method == 'median'): y_crit = np.median(y)\n",
    "    \n",
    "    if (method == 'median1050'): \n",
    "        y_crit = np.median(y)\n",
    "        if y_crit < 0.1: y_crit = 0.1\n",
    "        if y_crit > 0.5: y_crit = 0.5\n",
    "    \n",
    "    if (method == 'mean'): y_crit = np.mean(y)\n",
    "    \n",
    "    if (method == 'all'): y_crit = 0\n",
    "    \n",
    "    if x >= y_crit:\n",
    "        return y_crit, True\n",
    "    else:\n",
    "        return y_crit, False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Convert timestamps\n",
    "This cell converts the start time ```pan_time_start``` into the correct format for use in queries, etc, and calculates the corresponding ```pan_time_stop```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Converts string timestamp (e.g, \"2020-01-01 00:00:40.958\") to format allowing use of arithmatic operaters\n",
    "def pan_ts_convert(tstamp):\n",
    "    new_tstamp = -1\n",
    "    ltstamp = len(tstamp)\n",
    "    if ltstamp >= 23: \n",
    "        new_tstamp = datetime.strptime(str(tstamp).strip(), \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    else:\n",
    "        if ltstamp == 19:\n",
    "            new_tstamp = datetime.strptime(str(tstamp).strip(), \"%Y-%m-%d %H:%M:%S\")\n",
    "        else:\n",
    "            if ltstamp == 10: \n",
    "                new_tstamp = datetime.strptime(str(tstamp).strip(), \"%Y-%m-%d\")\n",
    "            else:\n",
    "                print('timestamp conversion problem:', tstamp)\n",
    "    return new_tstamp\n",
    "\n",
    "pan_time_start = pan_ts_convert(pan_time_start)\n",
    "pan_time_stop = pan_time_start + pd.Timedelta(seconds=pan_time_interval)\n",
    "\n",
    "if VERBOSE: print('Time range:', pan_time_start, pan_time_stop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load data from detected anomalies database\n",
    "In the online version of Panomaly, only a minimum of relevant data is loaded from each table - just what is needed to complete the analysis for the current time interval.\n",
    "\n",
    "In this offline demonstration verison of Panomaly, an anonymized subset of data is read from locally stored csv files, rather than pulling the data on-the-fly from the online databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input table names\n",
    "pan_table_list = ['app', 'metric', 'anomaly', 'anomaly_event']\n",
    "\n",
    "# Input CSV sample data file names\n",
    "pan_table_files = ['panomaly_'+table+'_sample_data.csv' for table in pan_table_list]\n",
    "\n",
    "# Output dataframe names\n",
    "pan_df_list = [table+'_df' for table in pan_table_list]\n",
    "\n",
    "# The dataframes will be stored in a dictionary\n",
    "pan_processed_dfs_dict = dict()\n",
    "\n",
    "# Loop over the input/output names\n",
    "for item_in, item_out in zip(pan_table_files, pan_df_list):\n",
    "    if VERBOSE: print(item_in, item_out)\n",
    "    pan_processed_dfs_dict[item_out] = pd.read_csv('./sample_data/'+item_in)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Clean the processed dataframes for missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing id value\n",
    "pan_processed_dfs_dict['anomaly_df'].dropna(subset=['id'], inplace=True)\n",
    "pan_processed_dfs_dict['metric_df'].dropna(subset=['id'], inplace=True)\n",
    "pan_processed_dfs_dict['app_df'].dropna(subset=['id'], inplace=True)\n",
    "\n",
    "# Remove rows with missing cross-reference id value(s)\n",
    "pan_processed_dfs_dict['anomaly_df'].dropna(subset=['metric_id'], inplace=True)\n",
    "pan_processed_dfs_dict['metric_df'].dropna(subset=['app_id'], inplace=True)\n",
    "pan_processed_dfs_dict['metric_df'].dropna(subset=['name'], inplace=True)\n",
    "pan_processed_dfs_dict['app_df'].dropna(subset=['organization_id'], inplace=True)\n",
    "pan_processed_dfs_dict['anomaly_event_df'].dropna(subset=['anomaly_id'], inplace=True)\n",
    "pan_processed_dfs_dict['anomaly_event_df'].dropna(subset=['event'], inplace=True)\n",
    "pan_processed_dfs_dict['anomaly_event_df'].dropna(subset=['occurred_at'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load data from raw events database\n",
    "In the online version of Panomaly, only a minimum of relevant data is loaded from each table - just what is needed to complete the analysis for the current time interval.\n",
    "\n",
    "In this offline demonstration verison of Panomaly, an anonymized subset of data is read from locally stored csv files, rather than pulling the data on-the-fly from the online databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan_raw_df = pd.read_csv('./sample_data/panomaly_raw_events_sample_data.csv')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Clean the raw dataframe for missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VERBOSE: print('Raw data length before cleaning:', len(pan_raw_df))\n",
    "\n",
    "# Remove rows with missing timestamp\n",
    "pan_raw_df.dropna(subset=['timestamp'], inplace=True)\n",
    "\n",
    "if VERBOSE: print('Raw data length after timestamp cleaning:', len(pan_raw_df))\n",
    "\n",
    "# Remove rows with missing event\n",
    "pan_raw_df.dropna(subset=['event'], inplace=True)\n",
    "\n",
    "if VERBOSE: print('Raw data length after event cleaning:', len(pan_raw_df))\n",
    "\n",
    "# Replace userId = None with userId = 'None'\n",
    "# This conglomerates all unnamed users into a single user named 'None'\n",
    "# User 'None' is actually useful, because it signals a user who clicked on the \n",
    "# signup page but did not register, so no userId exists for them.\n",
    "pan_raw_df.loc[pan_raw_df['userId'].isnull(), 'userId'] = 'None'\n",
    "# or comment the line above and uncomment the line below to delete all entries with unnamed users\n",
    "#pan_raw_df.dropna(subset=['userId'], inplace=True)\n",
    "                \n",
    "if VERBOSE: print('Raw data length after userId cleaning:', len(pan_raw_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataframe pretty print options for testing\n",
    "\n",
    "# Reference(s):\n",
    "# https://towardsdatascience.com/pretty-displaying-tricks-for-columnar-data-in-python-2fe3b3ed9b83\n",
    "# https://thispointer.com/python-pandas-how-to-display-full-dataframe-i-e-print-all-rows-columns-without-truncation/\n",
    "\n",
    "if VERBOSE:\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.options.display.width = None\n",
    "    pd.options.display.max_colwidth = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Build the master anomaly dataframe\n",
    "This dataframe correlates all of the information in the other processed data (from the postgreSQL DB) dataframes to match up anomalies, metrics, apps, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match metric id with anomaly id\n",
    "pan_ma_df = pan_processed_dfs_dict['anomaly_df'][['id', 'metric_id']].copy()\n",
    "pan_ma_df.rename(columns={'id':'id_anom', 'metric_id':'id_metric'}, inplace=True)\n",
    "\n",
    "# Match app id with metric id\n",
    "pan_ma_df = pan_ma_df.join(pan_processed_dfs_dict['metric_df'].set_index('id').loc[:, ['app_id']], on='id_metric')\n",
    "pan_ma_df.rename(columns={'app_id':'id_app'}, inplace=True)\n",
    "\n",
    "# Match organization id and mongo_collection with app id\n",
    "pan_ma_df = pan_ma_df.join(pan_processed_dfs_dict['app_df'].set_index('id').loc[:, ['organization_id']], on='id_app')\n",
    "pan_ma_df.rename(columns={'organization_id':'id_org'}, inplace=True)\n",
    "\n",
    "# Match anomaly start times with anomaly id\n",
    "pan_df_test = pan_processed_dfs_dict['anomaly_event_df'][(pan_processed_dfs_dict['anomaly_event_df'].anomaly_id.isin(pan_ma_df.id_anom.values)) \n",
    "                & (pan_processed_dfs_dict['anomaly_event_df'].event == 'STARTED')]\n",
    "pan_ma_df = pan_ma_df.merge(pan_df_test[['anomaly_id','occurred_at']], left_on='id_anom', right_on='anomaly_id')\n",
    "pan_ma_df.rename(columns={'occurred_at':'tstart_anom'}, inplace=True)\n",
    "pan_ma_df['tstart_anom'] = [pan_ts_convert(time) for time in pan_ma_df['tstart_anom']]\n",
    "del pan_ma_df['anomaly_id']\n",
    "\n",
    "# Import matching metric type\n",
    "pan_ma_df = pan_ma_df.join(pan_processed_dfs_dict['metric_df'].set_index('id').loc[:, ['type']], on='id_metric')\n",
    "pan_ma_df.rename(columns={'type':'metric_type'}, inplace=True)\n",
    "\n",
    "# Import matching metric/event name - this one is important because \n",
    "# it is the only link to matching all of the information in this \n",
    "# dataframe to the corresponding events in the raw data.\n",
    "pan_ma_df = pan_ma_df.join(pan_processed_dfs_dict['metric_df'].set_index('id').loc[:, ['name']], on='id_metric')\n",
    "pan_ma_df.rename(columns={'name':'metric_name'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Clean the master anomaly dataframe\n",
    "This gets rid of all entries in the master anomaly dataframe that do not pertain to the selected app and org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VERBOSE: print('pan_ma_df length before cleaning:', len(pan_ma_df))\n",
    "\n",
    "# Remove missing values of id_app\n",
    "pan_ma_df.dropna(subset=['id_app'], inplace=True)\n",
    "pan_ma_df['id_app'] = pan_ma_df['id_app'].astype('int64')\n",
    "\n",
    "# Remove missing values of id_org\n",
    "pan_ma_df.dropna(subset=['id_org'], inplace=True)\n",
    "pan_ma_df['id_org'] = pan_ma_df['id_org'].astype('int64')\n",
    "\n",
    "if VERBOSE: print('pan_ma_df length before cleaning:', len(pan_ma_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Sort and correlate events, anomalies, and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the maximum value of metric_id, and will be used below to create new\n",
    "# metric numbers for events that are in the raw data but not in the metric table.\n",
    "pan_max_metric_id = max(pan_processed_dfs_dict['metric_df']['id'])\n",
    "\n",
    "# Define the name of the timestamp column in the raw events dataframe.\n",
    "pan_tcol_raw = 'timestamp'\n",
    "\n",
    "# The event channel is not currently being constrained, but here is where you could set the constraint.\n",
    "#pan_channel = 'client'\n",
    "\n",
    "# Define the names of the timestamp columns in the master anomaly dataframe.\n",
    "pan_tcol_ma_start  = 'tstart_anom'\n",
    "pan_tcol_ma_stop   = 'tstop_anom'\n",
    "\n",
    "# Select only the rows from the master anomaly dataframe relevant to the current app and org\n",
    "pan_ma_selected_df = pan_ma_df[(pan_ma_df[pan_tcol_ma_start] >= pan_time_start) \n",
    "                        & (pan_ma_df[pan_tcol_ma_start] < pan_time_stop) \n",
    "                        & (pan_ma_df['id_org'] == pan_org_id) \n",
    "                        & (pan_ma_df['id_app'] == pan_app_id)].reset_index()\n",
    "\n",
    "# Pull out lists for making comparisons\n",
    "if len(pan_ma_selected_df.index):\n",
    "    pan_anom_ids = pan_ma_selected_df['id_anom'].unique()\n",
    "\n",
    "    pan_metric_ids = pan_ma_selected_df[(pan_ma_selected_df.id_anom.isin(pan_anom_ids))].id_metric.to_list()\n",
    "    pan_nmetrics = len(pan_metric_ids)\n",
    "        \n",
    "    pan_metric_names = pan_ma_selected_df[(pan_ma_selected_df.id_anom.isin(pan_anom_ids))].metric_name.to_list()\n",
    "    \n",
    "    # This sorts all three lists in the same way so corresponding elements still match up in order\n",
    "    pan_anom_ids, pan_metric_ids, pan_metric_names = zip(*sorted(zip(pan_anom_ids, pan_metric_ids, pan_metric_names)))\n",
    "\n",
    "    pan_anom_ids = list(pan_anom_ids)\n",
    "    pan_metric_ids = list(pan_metric_ids)\n",
    "    pan_metric_names = list(pan_metric_names)\n",
    "\n",
    "# Find number and IDs of unique users\n",
    "pan_nusers = 0\n",
    "if len(pan_raw_df.index):\n",
    "    user_ids = pan_raw_df['userId'].unique()\n",
    "    pan_nusers = len(user_ids)\n",
    "\n",
    "    # Add metric ID to raw events dataframe\n",
    "    if len(pan_ma_selected_df.index):\n",
    "        pan_raw_df = pan_raw_df.join(pan_processed_dfs_dict['metric_df'].set_index('name').loc[:, ['id']], on='event')\n",
    "        pan_raw_df.rename(columns={'id':'id_metric'}, inplace=True)\n",
    "                \n",
    "        # Deal with unknown metric IDs by assigning a new (unused) metric ID number to them\n",
    "        # (i.e., events in pan_raw_df that are not listed in the metrics table with a corresponding id number)\n",
    "        if pan_raw_df['id_metric'].isnull().values.any:\n",
    "            pan_missing_metric_events = pan_raw_df[(pan_raw_df['id_metric'].isnull())].event\n",
    "            pan_missing_metric_events_unique = set(pan_missing_metric_events)\n",
    "\n",
    "            for item in pan_missing_metric_events_unique:\n",
    "                # Start the new metric id numbers at the current maximum metric id plus one\n",
    "                pan_max_metric_id += 1\n",
    "                pan_raw_df.at[pan_raw_df['event'] == item, 'id_metric'] = pan_max_metric_id\n",
    "        \n",
    "        # Create list of metrics and transitions between metrics for each user\n",
    "        pan_user_metrics_all = [] # list of metrics\n",
    "        pan_user_transitions = [] # list of metric transitions\n",
    "        \n",
    "        for user in user_ids:                \n",
    "            pan_user_metrics = (pan_raw_df[(pan_raw_df.userId == user)].id_metric.to_list())\n",
    "            pan_user_metrics_all += pan_user_metrics\n",
    "                        \n",
    "            for i in range(len(pan_user_metrics)-1):\n",
    "                pan_user_transitions.append([pan_user_metrics[i], pan_user_metrics[i+1]])\n",
    "        \n",
    "        pan_user_transitions_master = pan_user_transitions.copy()\n",
    "        \n",
    "        # Get rid of duplicates in metrics and transitions lists\n",
    "        pan_user_metrics_all = list(set(pan_user_metrics_all)) \n",
    "        pan_user_transitions = [list(x) for x in set(tuple(x) for x in pan_user_transitions)]\n",
    "    \n",
    "        # Get rid of cases where both events/metrics/nodes are the same\n",
    "        pan_user_transitions = [x for x in pan_user_transitions if len(set(x)) == 2]\n",
    "    else:\n",
    "        pan_user_metrics_all = []\n",
    "        pan_user_transitions = []\n",
    "\n",
    "if VERBOSE:\n",
    "    print('Valid events:       ', len(pan_raw_df))\n",
    "    print('Unique users:       ', pan_nusers)\n",
    "    print('Anomalies:          ', len(pan_ma_selected_df))\n",
    "    if len(pan_ma_selected_df.index):\n",
    "        print('                    ', pan_anom_ids)\n",
    "        print('Metrics:            ', pan_nmetrics)\n",
    "        print('                    ', pan_metric_ids)\n",
    "        print('                    ', pan_metric_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Check for anomalies and compile anomalies with zero user events\n",
    "If no anomalies are present, then we're done - the algorithm passes through to the end without trying to do more. This action is controlled by the value of ```panomaly_status```:\n",
    "\n",
    "* ```True``` = anomalies are present, continue\n",
    "* ```False``` = no anomalies are present, do not continue\n",
    "\n",
    "In some cases, anomalies are present without any corresponding user events (this is probably why they were anomalous), so I also deal with that case here. These \"zero event anomalies\" might be present with or without other anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list for storing the IDs of zero event anomalies\n",
    "pan_anom_zero_events = [] \n",
    "\n",
    "# Set panomaly_status\n",
    "if not len(pan_ma_selected_df.index): \n",
    "    panomaly_status = False\n",
    "    if VERBOSE: print('\\n*** WARNING! NO ANOMALIES! NO ADDITIONAL ANALYSIS WILL BE PERFORMED! ***\\n')\n",
    "else: \n",
    "    if not len(pan_raw_df.index):\n",
    "        panomaly_status = False\n",
    "    else: panomaly_status = True\n",
    "    \n",
    "    # Compile the zero event anomalies\n",
    "    for i, metric_name in enumerate(pan_metric_names):\n",
    "        if (metric_name not in pan_raw_df.event.to_string()):\n",
    "            pan_anom_zero_events.append([pan_anom_ids[i], pan_metric_ids[i], metric_name])\n",
    "    if pan_anom_zero_events:\n",
    "        if VERBOSE:\n",
    "            print('======================================')\n",
    "            print('The following metrics are probably flagged as anomalous becuase')\n",
    "            print('they have no user event triggers in the current interval:')\n",
    "            print(*pan_anom_zero_events, sep='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Build the linked anomalies dataframe\n",
    "This will be the main dataframe for storing diagnostic information about potentially linked anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "pan_la_df = []\n",
    "\n",
    "if panomaly_status:\n",
    "    temp_data_dict = {'N1': [], 'id_anom1':[], 'id_metric1':[], 'metric_name1':[], 'N2':[], 'id_anom2':[], 'id_metric2':[], 'metric_name2':[]}\n",
    "    for (a1, m1, n1), (a2, m2, n2) in itertools.product(zip(pan_anom_ids, pan_metric_ids, pan_metric_names), zip(pan_anom_ids, pan_metric_ids, pan_metric_names)):\n",
    "        # These values are transferred from pan_ma_df\n",
    "        temp_data_dict['id_anom1'].append(a1)\n",
    "        temp_data_dict['id_metric1'].append(m1)\n",
    "        temp_data_dict['metric_name1'].append(n1)\n",
    "        temp_data_dict['id_anom2'].append(a2)\n",
    "        temp_data_dict['id_metric2'].append(m2)\n",
    "        temp_data_dict['metric_name2'].append(n2)\n",
    "\n",
    "        # N1 and N2 are the number of events for each metric\n",
    "        temp_data_dict['N1'].append(len(pan_raw_df[(pan_raw_df['id_metric'] == m1)]))\n",
    "        temp_data_dict['N2'].append(len(pan_raw_df[(pan_raw_df['id_metric'] == m2)]))\n",
    "    \n",
    "    # Create the dataframe\n",
    "    pan_la_df = pd.DataFrame(temp_data_dict)\n",
    "\n",
    "    # Probability columns:\n",
    "    #     PbProb = Bayesian probability\n",
    "    #     PbNab = number of transitions from metric \"a\" to metric \"b\"\n",
    "    #     PfProb = frequentist probability\n",
    "    pan_la_df['PbProb'] = list(len(pan_la_df)*[0])\n",
    "    pan_la_df['PbNab'] = list(len(pan_la_df)*[0])\n",
    "    pan_la_df['PfProb'] = list(len(pan_la_df)*[0])\n",
    "\n",
    "    # Graph columns (containing graph metrics):\n",
    "    #     Gmod* = modularity class (nodes that share an overdensity of edges)\n",
    "    #     Gdeg* = degree (number of edges for a given node, as a fraction of the total number of nodes)\n",
    "    #     Gbtw* = betweennes (number of shortest paths between two nodes that pass through the given node)\n",
    "    #     Gevc* = eigenvector centrality (importance of a node measured by the number of \"important\" nodes connected to it)\n",
    "    pan_la_df['Gmod1'] = list(len(pan_la_df)*[-1])\n",
    "    pan_la_df['Gdeg1'] = list(len(pan_la_df)*[0])\n",
    "    pan_la_df['Gbtw1'] = list(len(pan_la_df)*[0])\n",
    "    pan_la_df['Gevc1'] = list(len(pan_la_df)*[0])\n",
    "    pan_la_df['Gavg1'] = list(len(pan_la_df)*[0])\n",
    "    pan_la_df['Gmod2'] = list(len(pan_la_df)*[-1])\n",
    "    pan_la_df['Gdeg2'] = list(len(pan_la_df)*[0])\n",
    "    pan_la_df['Gbtw2'] = list(len(pan_la_df)*[0])\n",
    "    pan_la_df['Gevc2'] = list(len(pan_la_df)*[0])\n",
    "    pan_la_df['Gavg2'] = list(len(pan_la_df)*[0])\n",
    "\n",
    "    # Transition class (see below for class descriptions)\n",
    "    pan_la_df['pan_class'] = list(len(pan_la_df)*[-1])\n",
    "\n",
    "    # Panomaly metrics\n",
    "    #    Qp = combined probability metric\n",
    "    #    Qg = combined graph metric\n",
    "    #    Qpan = final evaluation metric (combination of Qp and Qg)\n",
    "    #    Qcrit = critical threshhold for Qpan used to determine the verdict\n",
    "    pan_la_df['Qp'] = list(len(pan_la_df)*[0])\n",
    "    pan_la_df['Qg'] = list(len(pan_la_df)*[0])\n",
    "    pan_la_df['Qpan'] = list(len(pan_la_df)*[0])\n",
    "    pan_la_df['Qcrit'] = list(len(pan_la_df)*[1])\n",
    "\n",
    "    # Evaluation of whether or not the anomaly linkage should be surfaced to the client dashboard\n",
    "    pan_la_df['Verdict'] = list(len(pan_la_df)*[False])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bayesian Probability analysis\n",
    "Bayesian probability incorporates prior knowledge about the attributes of a system to inform the calculation of probabilities of a given event occurring based on knowing what previous event occurred.\n",
    "\n",
    "It is based on Bayes's Theorem:\n",
    "\n",
    "```P(A|B) = P(A)P(B|A)/P(B)```\n",
    "\n",
    "where \n",
    "\n",
    "* ```P(A|B)``` = the probability that event A occurs after event B - this is what we want to find.\n",
    "\n",
    "\n",
    "* ```P(A)``` = the probability that event A occurs irrespective of event B.\n",
    "\n",
    "\n",
    "* ```P(B)``` = the probability that event B occurs irrespective of event A.\n",
    "\n",
    "\n",
    "* ```P(B|A)``` = the probability that event B occurred after event A based on the data.\n",
    "\n",
    "In this case, we can define the events as\n",
    "\n",
    "**A**: metric2 = m2 (i.e., the 2nd metric is m2)    \n",
    "\n",
    "**B**: metric1 = m1 (i.e., the 1st metric is m1)\n",
    "\n",
    "and the probabilities are\n",
    "\n",
    "* ```P(A)= NA / Ntotal``` (# cases with metric2 = m2 / # all cases)\n",
    "\n",
    "\n",
    "* ```P(B)= NB / Ntotal``` (# cases with metric1 = m1 / # all cases)\n",
    "\n",
    "\n",
    "* ```P(B|A) = N(m1,m2) / NA``` (the probability that metric1 = m1 when metric2 = m2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if panomaly_status:\n",
    "    \n",
    "    from collections import Counter # This provides a dictionary subclass for counting hashable objects\n",
    "\n",
    "    # Count the number of each possible transitions between events (nodes)\n",
    "    pan_bayes_counter = Counter(tuple(x) for x in iter(pan_user_transitions_master))\n",
    "    pan_Ntotal = len(pan_user_transitions_master)\n",
    "\n",
    "    if VERBOSE:\n",
    "        print('All anomaly ids:', pan_anom_ids)\n",
    "        print('All anomaly metrics:', pan_metric_ids)\n",
    "        print('Total event transitions:', pan_Ntotal)\n",
    "        # N might be less than expected because some users only initiate a total of 1 event (i.e., no transitions between events)\n",
    "        print('Total unique event transitions:', len(pan_bayes_counter))\n",
    "        pan_Pcrit = 0.01 # critical probability threshold for reporting a potential linkage\n",
    "        print('Probability reporting threshold >= '+str(pan_pp(pan_Pcrit)).strip()+'%')\n",
    "\n",
    "    pan_set_metric_ids = set(pan_metric_ids) # use this to get probabilities for just unique anomaly metric transitions\n",
    "    #pan_set_metric_ids = pan_user_metrics_all # use this to get probabilities for all unique metric transitions\n",
    "    \n",
    "    for m1, m2 in itertools.product(pan_set_metric_ids, pan_set_metric_ids):\n",
    "        pan_A = sum([pan_bayes_counter[item] for item in pan_bayes_counter if item[1] == m2])\n",
    "        pan_B = sum([pan_bayes_counter[item] for item in pan_bayes_counter if item[0] == m1])\n",
    "        pan_BA = (pan_bayes_counter[(m1, m2)])\n",
    "\n",
    "        if (pan_Ntotal > 0) & (pan_A > 0):\n",
    "            pan_PA  = pan_A/pan_Ntotal\n",
    "            pan_PBA = pan_BA/pan_A\n",
    "            pan_PB  = pan_B/pan_Ntotal\n",
    "\n",
    "            if (pan_PB > 0): \n",
    "                pan_PAB = pan_PA*pan_PBA/pan_PB\n",
    "                    \n",
    "                if VERBOSE: \n",
    "                    if (pan_PAB >= pan_Pcrit): print(m1,'+',m2,': P(%) =',pan_pp(pan_PAB),' [N_AB = '+str(pan_BA)+']')\n",
    "\n",
    "                if (pan_PAB > 0):\n",
    "                    PbProb = float(pan_PAB)\n",
    "                    pan_la_df.at[((pan_la_df['id_metric1'] == m1) & (pan_la_df['id_metric2'] == m2)), 'PbProb'] = [PbProb]\n",
    "                        \n",
    "                    PbNab = int(pan_BA)\n",
    "                    pan_la_df.at[((pan_la_df['id_metric1'] == m1) & (pan_la_df['id_metric2'] == m2)), 'PbNab'] = [PbNab]\n",
    "                        \n",
    "                    PfProb = float(pan_BA/pan_Ntotal)\n",
    "                    pan_la_df.at[((pan_la_df['id_metric1'] == m1) & (pan_la_df['id_metric2'] == m2)), 'PfProb'] = [PfProb]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Network Graph analysis\n",
    "I apply fairly  standard network graph analysis techniques, using the Python module ```networkx```.\n",
    "\n",
    "Networks consist of nodes (the events) and edges (the transitions between events). I am using an undirected, weighted network. Undirected means that transitions between events are allowed to go in either direction (i.e., A to B and B to A). Weighted means that the edges are weighted by the total number of corresponding transitions, to allow for the \"popularity\" or \"importance\" of certain sequences of events (as evidenced by the actions of the users).\n",
    "\n",
    "Note: in a fresh installation of Anaconda, the following additional package must be installed to provide some fo the graph analysis functionality.\n",
    "\n",
    "```pip install python-louvain```\n",
    "\n",
    "Note: instances of ```G.node[]``` have been changed to ```G.nodes[]``` for compatibility with networkx 2.4+.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These commands should really be at the top of the next cell, but they\n",
    "# are here because of a known bug between matplotlib and Jupyter Notebooks \n",
    "# that makes displaying a figure fail during the first run after starting \n",
    "# or restarting the kernel if the matplotlib import is done in the same \n",
    "# cell as the plot.\n",
    "\n",
    "# Reference(s):\n",
    "#     https://github.com/jupyter/notebook/issues/3670\n",
    "\n",
    "if panomaly_status:\n",
    "    if VERBOSE:\n",
    "        import time # used for establishing a random seed for plotting\n",
    "        import matplotlib.pyplot as plt # for making graph plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if panomaly_status:\n",
    "    import community # This is the python-louvain package\n",
    "    import networkx as nx\n",
    "    from operator import itemgetter\n",
    "\n",
    "    pan_nodes = pan_user_metrics_all.copy() # These are the events\n",
    "    pan_Nnodes = len(pan_nodes)    \n",
    "    pan_edges = pan_user_transitions.copy() # These are the transitions between events\n",
    "    \n",
    "    # Get rid of transitions where both nodes are the same (i.e., not really a transition) \n",
    "    # but keep duplicate transitions.\n",
    "    pan_user_transitions_wts = [x for x in pan_user_transitions_master if len(set(x)) == 2]\n",
    "    pan_edge_wts = Counter(tuple(x) for x in iter(pan_user_transitions_wts))\n",
    "        \n",
    "    # Create list of edge weights\n",
    "    # pan_wedges_friends = weight is the number of observed transitions from all users; appropriate \n",
    "    #     for finding modularity & eigencentrality, because it implies the strength of \"friendship\" between nodes\n",
    "    # pan_wedges_enemies = weights reversed from pan_wedges_friends; appropriate for finding \n",
    "    #     betweenness, which assumes high weight indicates a \"high cost\" (i.e., \"bad\") transition\n",
    "    # e.g., see Santiago Segarra and Alejandro Ribeiro, \"Stability and Continuity of Centrality Measures in \n",
    "    #     Weighted Graphs\", https://arxiv.org/pdf/1410.5119.pdf; M. E. J. Newman, PHYSICAL REVIEW E 70, 056131 \n",
    "    #     (2004), \"Analysis of weighted networks\", http://www.uvm.edu/pdodds/files/papers/others/2004/newman2004d.pdf\n",
    "    pan_wedges_friends = []    \n",
    "    [pan_wedges_friends.append(tuple([edge[0], edge[1], pan_edge_wts[tuple(edge)]])) for edge in pan_edges]\n",
    "    #[pan_wedges_friends.append(tuple([edge[0], edge[1], 1])) for edge in pan_edges]\n",
    "    wt_min = min([item[2] for item in pan_wedges_friends])\n",
    "    wt_max = max([item[2] for item in pan_wedges_friends])\n",
    "    pan_wedges_enemies = []    \n",
    "    [pan_wedges_enemies.append(tuple([edge[0], edge[1], wt_max-pan_edge_wts[tuple(edge)]+wt_min])) for edge in pan_edges]\n",
    "    #pan_wedges_enemies = pan_wedges_friends.copy()    \n",
    "\n",
    "    # Initialize empty graph\n",
    "    G = nx.Graph()\n",
    "    # Populate the nodes\n",
    "    G.add_nodes_from(pan_nodes)\n",
    "    # Populate the weighted edges\n",
    "    G.add_weighted_edges_from(pan_wedges_friends, weight='weight_friends') \n",
    "    G.add_weighted_edges_from(pan_wedges_enemies, weight='weight_enemies') \n",
    "\n",
    "    # Calculate graph metrics...\n",
    "    \n",
    "    # DEGREE = the number of connections (edges) a node has to other nodes, as a fraction \n",
    "    # of the total number of nodes in the network\n",
    "    pan_degree_dict = dict(G.degree(G.nodes()))\n",
    "    nx.set_node_attributes(G, pan_degree_dict, 'degree') # assign as node attribute\n",
    "\n",
    "    # BETWEENNESS CENTRALITY = the number of times a node lies on the shortest path \n",
    "    # between two other nodes.\n",
    "    pan_betweenness_dict = nx.betweenness_centrality(G, weight='weight_enemies') # obtain betweenness centrality\n",
    "    nx.set_node_attributes(G, pan_betweenness_dict, 'betweenness') # assign as node attribute\n",
    "    \n",
    "    for i in pan_metric_ids:\n",
    "        if i in pan_degree_dict:\n",
    "            pan_la_df.at[((pan_la_df['id_metric1'] == i)), 'Gdeg1'] = pan_degree_dict[i]/pan_Nnodes\n",
    "            pan_la_df.at[((pan_la_df['id_metric2'] == i)), 'Gdeg2'] = pan_degree_dict[i]/pan_Nnodes\n",
    "\n",
    "        if i in pan_betweenness_dict:\n",
    "            pan_la_df.at[((pan_la_df['id_metric1'] == i)), 'Gbtw1'] = pan_betweenness_dict[i]\n",
    "            pan_la_df.at[((pan_la_df['id_metric2'] == i)), 'Gbtw2'] = pan_betweenness_dict[i]        \n",
    "    \n",
    "    # MODULARITY CLASSES have dense connections between the nodes within the modularity \n",
    "    # classes but sparse connections between nodes in different modules.\n",
    "    \n",
    "    # The following try/except block is here because of an early problem caused by uncleaned \n",
    "    # data (events with unnumbered metrics) which has now been fixed. So, the exception  \n",
    "    # should never be reached here - but why not keep it anyway, just in case...\n",
    "    try:\n",
    "        pan_modularity_classes = community.best_partition(G, weight='weight_friends')\n",
    "    except KeyError:\n",
    "        print('KeyError in community.best_partition - canceling remainder of Graph analysis')\n",
    "        panomaly_status = False\n",
    "        \n",
    "        \n",
    "    # Continued after the following VERBOSE block...\n",
    "    \n",
    "        \n",
    "    # Lots of diagnostic information will be displayed in verbose mode. None of this \n",
    "    # is necessary for the anomaly linkage analysis. The necessary stuff is outside \n",
    "    # the VERBOSE block.\n",
    "    if VERBOSE:\n",
    "        # Basic network information\n",
    "        print(nx.info(G))\n",
    "        \n",
    "        # Network density is the number of edges (transitions between nodes) that \n",
    "        # exist divided by the total number of all edges that could exist (regardless \n",
    "        # of whether or not they do).\n",
    "        pan_density = nx.density(G)\n",
    "        print(\"Network density:\", pan_density)\n",
    "        print('--------------------------------')\n",
    "\n",
    "        # Graph components are (sub)sets of nodes that have no edges connecting them. \n",
    "        # Often a graph will have only one component, with at least one edge connecting \n",
    "        # all nodes. Such a graph is also called \"connected\". But sometimes two or more \n",
    "        # groups of \"disconnected\" nodes are present. In the user interactions scenario, \n",
    "        # I see some graphs with up to several disconnected components, typically \n",
    "        # containing only 1 or 2 nodes. These likely correspond to users who interacted  \n",
    "        # only shortly with the app and performed a couple of infrequently used actions.       \n",
    "        # \n",
    "        # The following statement returns False for a disconnected graph:\n",
    "        pan_single_component = nx.is_connected(G)\n",
    "        print('Is this a single-component network?', pan_single_component)\n",
    "        \n",
    "        # Network diameter is the longest path (number of edges) connecting two nodes.\n",
    "        if (pan_single_component == True): \n",
    "            print('Single Component Network Diamter = ', nx.diameter(G))\n",
    "\n",
    "        # Diameter cannot be directly calculated for a disconnected graph, so the \n",
    "        # diameter of the largest component is used instead.\n",
    "        # nx.connected_components returns a list of the graph components, and\n",
    "        # max() finds the largest one.\n",
    "        pan_components = nx.connected_components(G)\n",
    "        pan_largest_component = max(pan_components, key=len)\n",
    "\n",
    "        # Create a subgraph of just the largest component and return its diameter.\n",
    "        pan_subgraph = G.subgraph(pan_largest_component)\n",
    "        print(\"Network diameter of largest component:\", nx.diameter(pan_subgraph))\n",
    "        print('--------------------------------')\n",
    "        \n",
    "        pan_sorted_degree = sorted(pan_degree_dict.items(), key=itemgetter(1), reverse=True)\n",
    "        print(\"Top 20 nodes by degree:\")\n",
    "        [print(d) for d in pan_sorted_degree[:20]]\n",
    "        print('--------------------------------')\n",
    "        \n",
    "        pan_sorted_betweenness = sorted(pan_betweenness_dict.items(), key=itemgetter(1), reverse=True)\n",
    "        print(\"Top 20 nodes by betweenness centrality:\")\n",
    "        [print(b) for b in pan_sorted_betweenness[:20]]\n",
    "        print('--------------------------------')\n",
    "        \n",
    "        # Get the top 20 nodes by betweenness as a list\n",
    "        pan_top_betweenness = pan_sorted_betweenness[:20]\n",
    "        # Then find and print their degree\n",
    "        for tb in pan_top_betweenness: # Loop through pan_top_betweenness\n",
    "            pan_degree = pan_degree_dict[tb[0]] # Use pan_degree_dict to get a node's degree\n",
    "            print(\"Name:\", tb[0], \"| Betweenness Centrality:\", tb[1], \"| Degree:\", pan_degree)\n",
    "        print('--------------------------------')\n",
    "        \n",
    "        if panomaly_status:\n",
    "            pan_global_modularity = community.modularity(pan_modularity_classes, G)\n",
    "            print(\"Global Modularity =\", pan_global_modularity)\n",
    "            print('--------------------------------')\n",
    "            print(\"Modularity Class Sorted by Eigenvector Centrality:\")\n",
    "\n",
    "            \n",
    "    if panomaly_status:\n",
    "        nx.set_node_attributes(G, pan_modularity_classes, 'modularity') # assign as node attribute\n",
    "    \n",
    "        # EIGENVECTOR CENTRALITY = a measure of the influence of a node in a network; a high \n",
    "        # eigenvector centrality means that a node is connected to many nodes who themselves \n",
    "        # have high scores.   \n",
    "        pan_eigenvector_dict = nx.eigenvector_centrality(G, weight='weight_friends') # obtain eigenvector centrality\n",
    "        nx.set_node_attributes(G, pan_eigenvector_dict, 'eigenvector') # assign as node attribute\n",
    "   \n",
    "        # Sort nodes into modularity classes\n",
    "        pan_modularity_dict = {} # Create a new, empty dictionary\n",
    "        for k,v in pan_modularity_classes.items(): # Loop through the modularity classes dictionary\n",
    "            if v not in pan_modularity_dict:\n",
    "                pan_modularity_dict[v] = [k] # Add a new key for a modularity class that hasn't been seen before\n",
    "            else:\n",
    "                pan_modularity_dict[v].append(k) # Append a name to the list for a modularity class that has already been seen\n",
    "\n",
    "                \n",
    "        if VERBOSE:\n",
    "            # pan_G_modularity_class_dict is a remnant of early code development. \n",
    "            # It is no longer used in the final algorithm, but it contains a useful compilation \n",
    "            # of information and is a little difficult to populate the dictionary, so I have \n",
    "            # left the code in. It only runs in verbose mode.\n",
    "            pan_G_modularity_class_dict = {'Gmodclass':[], 'GNmodclass':[], 'GmodMembers':[], 'Gmodanoms':[], 'Ganomevents':[]}\n",
    "                # Gmodclass = modularity class identifier (integer number)\n",
    "                # GNmodclass = number of nodes in modularity class\n",
    "                # GmodMembers = list of nodes in modularity class\n",
    "                # Gmodanoms = list of anomalous metrics in modularity class\n",
    "                # Ganomevents = list of anomalous metric event names in modularity class\n",
    "        \n",
    "        \n",
    "        for k,v in pan_modularity_dict.items(): # Loop through the new modularity classes dictionary\n",
    "            # Cannot ignore single-member modularity classes because a disconnected anomalous \n",
    "            # metric would not be surfaced as linked to itself (if appropropriate).\n",
    "            if len(v) > 0:   \n",
    "                # Get a list of just the nodes in that class\n",
    "                pan_classN = [n for n in G.nodes() if G.nodes[n]['modularity'] == k]\n",
    "\n",
    "                # Create a dictionary of the eigenvector centralities of those nodes\n",
    "                pan_classN_eigenvector = {n:G.nodes[n]['eigenvector'] for n in pan_classN}\n",
    "\n",
    "                # Sort the eigencentrality dictionary\n",
    "                pan_classN_sorted_by_eigenvector = sorted(pan_classN_eigenvector.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "                # Add results to the linked anomalies dataframe\n",
    "                for node in pan_classN_sorted_by_eigenvector:\n",
    "                    pan_la_df.at[((pan_la_df['id_metric1'] == node[0])), 'Gmod1'] = k\n",
    "                    pan_la_df.at[((pan_la_df['id_metric2'] == node[0])), 'Gmod2'] = k\n",
    "\n",
    "                    pan_la_df.at[((pan_la_df['id_metric1'] == node[0])), 'Gevc1'] = node[1]\n",
    "                    pan_la_df.at[((pan_la_df['id_metric2'] == node[0])), 'Gevc2'] = node[1]\n",
    "                    \n",
    "                    if VERBOSE: print('Class:', k, '| Name:', node[0], '| Eigenvector Centrality:', node[1])\n",
    "\n",
    "                        \n",
    "                if VERBOSE:\n",
    "                    pan_G_modularity_class_dict['Gmodclass'].append(str(k))\n",
    "                    pan_G_modularity_class_dict['GNmodclass'].append(str(len(v)))\n",
    "                    pan_G_modularity_class_dict['GmodMembers'].append(v)\n",
    "\n",
    "                    # This is the list of anomalies in the current modularity class\n",
    "                    pan_anom_metrics = list(set(pan_metric_ids).intersection(v))\n",
    "                    pan_G_modularity_class_dict['Gmodanoms'].append(pan_anom_metrics)\n",
    "                \n",
    "                    print('Modularity Class Metrics:', pan_classN)\n",
    "                    if pan_anom_metrics: \n",
    "                        print('Included Anomaly Metrics:', pan_anom_metrics)\n",
    "\n",
    "                    # Pull out the event names of anomalous metrics in modularity classes\n",
    "                    pan_metric_idx = [pan_metric_ids.index(x) for x in pan_anom_metrics]\n",
    "                    if pan_metric_idx: \n",
    "                        pan_metric_names_output = [pan_metric_names[x] for x in pan_metric_idx]\n",
    "                        print('                         ', pan_metric_names_output)                        \n",
    "                    else:\n",
    "                        pan_metric_names_output = []\n",
    "\n",
    "                    pan_G_modularity_class_dict['Ganomevents'].append(pan_metric_names_output)\n",
    "                    print('')        \n",
    "\n",
    "        if VERBOSE:\n",
    "            pan_G_modularity_class_df = pd.DataFrame(pan_G_modularity_class_dict)\n",
    "            print('--------------------------------')    \n",
    "            print('All anomaly metrics:', pan_metric_ids)\n",
    "\n",
    "            #### PLOT GRAPH\n",
    "            print('--------------------------------')    \n",
    "            print('\\nNetwork Graph.')\n",
    "            print('Nodes are size-coded by degree and color-coded by modularity class.')\n",
    "            print('Anomalies are shown as red diamonds (with metric_ids labeled).')\n",
    "            \n",
    "            # Prepare node labels for plotting the Graph\n",
    "            pan_node_labels = {}    \n",
    "            for node in G.nodes():\n",
    "                if node in pan_metric_ids:\n",
    "                    # Set the node name as the key and the label as its value \n",
    "                    pan_node_labels[node] = node\n",
    "\n",
    "            # This is the current sytem time to use as a seed for the plot\n",
    "            pan_draw_seed = round(time.time()) # has to be an integer between 1 and (2**32 - 1)\n",
    "            # The spring plot imagines the edges as springs with spring constant kspring. \n",
    "            # The network is spun around its center and \"stretches\" the nodes apart \n",
    "            # to make the network legible.\n",
    "            kspring = 7.0/np.sqrt(pan_Nnodes)\n",
    "            pos = nx.spring_layout(G, k=kspring, seed=pan_draw_seed)\n",
    "            \n",
    "            # If the graph analysis happened, color-code the nodes by modularity class; otherwise, use blue\n",
    "            if panomaly_status:\n",
    "                pan_node_color = [G.nodes[value]['modularity'] for value in G.nodes]\n",
    "            else:\n",
    "                pan_node_color = 'b'\n",
    "\n",
    "            # Size-code the nodes by their degree\n",
    "            pan_node_size0 = [G.nodes[value]['degree'] for value in G.nodes]\n",
    "            pan_max_node_size = max(pan_node_size0)\n",
    "            pan_min_node_size = 15\n",
    "            pan_node_size_scale_factor = 80\n",
    "            pan_node_size = [(pan_min_node_size + pan_node_size_scale_factor*(value/pan_max_node_size)) for value in pan_node_size0]\n",
    "\n",
    "            # Set up the figure\n",
    "            f = plt.figure(figsize=[6,6], dpi=600)\n",
    "            ax = f.add_subplot(1, 1, 1)\n",
    "\n",
    "            # Plot the network\n",
    "            nx.draw(G, pos, ax=ax, cmap=plt.get_cmap('viridis'), vmin=min(pan_node_color), vmax=max(pan_node_color), node_color=pan_node_color, node_size=pan_node_size, with_labels=False, width=0.25)\n",
    "\n",
    "            # Overplot the anomalies as large red diamonds\n",
    "            for metric_id in pan_node_labels:\n",
    "                value = G.nodes[metric_id]['degree']\n",
    "                pan_node_size = (pan_min_node_size + pan_node_size_scale_factor*(value/pan_max_node_size))\n",
    "                nx.draw_networkx_nodes(G, pos, node_size=pan_node_size, node_shape='D', nodelist=[metric_id], node_color='r')\n",
    "\n",
    "            # Label just the anomalies with their metric ID\n",
    "            nx.draw_networkx_labels(G, pos, pan_node_labels, font_size=4, font_color='k')\n",
    "\n",
    "            # Uncomment the next line to save the network graph figure to disk\n",
    "            #plt.savefig('figures/graph'+str(pan_draw_seed)+'.png') # save as png\n",
    "\n",
    "            plt.show() # display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Combine probabilities\n",
    "Now that the Graph analysis is done, one more thing to do for the probability analysis: combine the probabilities for mirror image transitions (A to B and B to A) because we don't care in which direction anomalies are linked, just that they are linked. It's a \"this or that\" situation, so the probabilities for the two cases can just be added together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if panomaly_status:\n",
    "    # Going to work in a copy of the linked anomalies dataframe, then copy it back to the original frame at the end\n",
    "    pan_la_temp_df = pan_la_df.copy()\n",
    "\n",
    "    # Loop through the dataframe and find rows that have the same transition\n",
    "    pan_used_idx = []\n",
    "    for m1, m2 in itertools.product(pan_set_metric_ids, pan_set_metric_ids):\n",
    "        if m1 != m2:\n",
    "            pan_temp_df0 = pan_la_df[(pan_la_df.id_metric1 == m1) & (pan_la_df.id_metric2 == m2)].copy()\n",
    "            pan_temp_df1 = pan_la_df[(pan_la_df.id_metric1 == m2) & (pan_la_df.id_metric2 == m1)].copy()\n",
    "                \n",
    "            if (len(pan_temp_df0.index) > 0):\n",
    "                if (not pan_temp_df0.index.isin(pan_used_idx)):\n",
    "                    pan_used_idx.append(pan_temp_df0.index[0])\n",
    "                    if (len(pan_temp_df1.index) > 0): \n",
    "                        # Record the indices so we don't try to operate on the same row(s) twice\n",
    "                        pan_used_idx.append(pan_temp_df1.index[0])\n",
    "                        # Combine the probabilities\n",
    "                        pan_Psum = (pan_temp_df0.iloc[0]['PbProb'] + pan_temp_df1.iloc[0]['PbProb'])\n",
    "                        pan_Nsum = (pan_temp_df0.iloc[0]['PbNab'] + pan_temp_df1.iloc[0]['PbNab'])\n",
    "                        pan_Pfsum = (pan_temp_df0.iloc[0]['PfProb'] + pan_temp_df1.iloc[0]['PfProb'])\n",
    "            \n",
    "                        # Populate the revised row to the dataframe\n",
    "                        pan_la_temp_df.at[pan_temp_df0.index[0], 'PbProb'] = pan_Psum\n",
    "                        pan_la_temp_df.at[pan_temp_df0.index[0], 'PbNab'] = pan_Nsum\n",
    "                        pan_la_temp_df.at[pan_temp_df0.index[0], 'PfProb'] = pan_Pfsum\n",
    "\n",
    "                        # Get rid of the now redundant row\n",
    "                        pan_la_temp_df = pan_la_temp_df[pan_la_temp_df.index != pan_temp_df1.index[0]]\n",
    "    \n",
    "    # Copy the working dataframe back to the original dataframe\n",
    "    pan_la_df = pan_la_temp_df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Housekeeping\n",
    "Account for the (uninteresting) case when there is only 1 anomaly and it is not linked to itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if panomaly_status:\n",
    "    if pan_nmetrics == 1:\n",
    "        if pan_la_df[pan_la_df['id_metric1'] == pan_metric_ids[0]].PbNab.to_list()[0] < 1: panomaly_status = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Combine metrics\n",
    "Combine the probability and graph metrics into a single metric for each analysis. I used Latent Factor Analysis to confirm that all of the individual metrics are related by a common underlying (but unknown) relationship (positive correlation), which makes it appropriate to combine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if panomaly_status: \n",
    "    # The probability metric Qp is created by combining the Bayesian probability \n",
    "    # and the frequentist probability using the combine_scores method. This \n",
    "    # downweights cases where the Bayesian probability is dependent on a small \n",
    "    # number of actual instances.\n",
    "    Qp = combine_scores((pan_la_df['PbProb']), (pan_la_df['PfProb']))\n",
    "    Qp_max = max(Qp)\n",
    "    pan_la_df['Qp'] = Qp\n",
    "\n",
    "    # The graph metric Qg is created by averaging the 3 graph metrics for each \n",
    "    # node in a transition, then using the combine_scores method on the two \n",
    "    # average values.\n",
    "    pan_avg_divisor = 3\n",
    "    pan_la_df['Gavg1'] = (pan_la_df['Gdeg1'] + pan_la_df['Gbtw1'] + pan_la_df['Gevc1']) / pan_avg_divisor\n",
    "    pan_la_df['Gavg2'] = (pan_la_df['Gdeg2'] + pan_la_df['Gbtw2'] + pan_la_df['Gevc2']) / pan_avg_divisor\n",
    "\n",
    "    Qg = combine_scores(pan_la_df['Gavg1'], pan_la_df['Gavg2'])\n",
    "    Qg_max = max(Qg)\n",
    "    pan_la_df['Qg'] = Qg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Sort linked anomalies into classes\n",
    "The linked anomalies are assigned to a class based on the following criteria:\n",
    "\n",
    "* **Class 4** = Anomalies linked to themselves, resulting from users that triggered the same event multiple times in succession. These also have high Qp and Qg values.\n",
    "\n",
    "\n",
    "* **Class 3** = Linked anomalies with agreement between the graph and probability analyses (high Qp and Qg). These are the most reliable linkages.\n",
    "\n",
    "\n",
    "* **Class 2** = Anomalies linked by a high Qp value only (i.e., they are not members of the same modularity class, so have Qg = 0). Less reliable linkages.\n",
    "\n",
    "\n",
    "* **Class 1** = Anomalies linked by the graph analysis only (i.e., they are members of the same modularity class). There were no actual user events linking these anomalies (PbNab = 0). Exercise caution: the graph analysis predicts that these anomalies would be linked, but we have no data showing that users transitioned from one event to the other.\n",
    "\n",
    "\n",
    "* **Class 0** = Metrics that are anomalous during the current time interval because they have no user events (i.e., no user clicked on this event during this hour, but users did in past hours).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan_classes = [4, 3, 2, 1]\n",
    "pan_class_tags = {0:'No user events', 1:'G only', 2:'Pb only', 3:'Pb & G', 4:'Pb & G (self)'}\n",
    "\n",
    "if panomaly_status: \n",
    "    pan_la_df.loc[(pan_la_df['id_metric1'] != pan_la_df['id_metric2']) & (pan_la_df['PbNab'] < 1) & ((pan_la_df['Gmod1'] >= 0) & (pan_la_df['Gmod2'] >= 0)) & (pan_la_df['Gmod1'] == pan_la_df['Gmod2']), 'pan_class'] = 1\n",
    "    pan_la_df.loc[(pan_la_df['id_metric1'] != pan_la_df['id_metric2']) & (pan_la_df['PbNab'] > 0) & ((pan_la_df['Gmod1'] >= 0) & (pan_la_df['Gmod2'] >= 0)) & (pan_la_df['Gmod1'] != pan_la_df['Gmod2']), 'pan_class'] = 2\n",
    "    pan_la_df.loc[(pan_la_df['id_metric1'] != pan_la_df['id_metric2']) & (pan_la_df['PbNab'] > 0) & ((pan_la_df['Gmod1'] >= 0) & (pan_la_df['Gmod2'] >= 0)) & (pan_la_df['Gmod1'] == pan_la_df['Gmod2']), 'pan_class'] = 3\n",
    "    pan_la_df.loc[(pan_la_df['id_metric1'] == pan_la_df['id_metric2']) & (pan_la_df['PbNab'] > 0) & ((pan_la_df['Gmod1'] >= 0) & (pan_la_df['Gmod2'] >= 0)) & (pan_la_df['Gmod1'] == pan_la_df['Gmod2']), 'pan_class'] = 4\n",
    "\n",
    "# Class 0 assignments are done later in the code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Housekeeping\n",
    "Account for the case when no anomaly is assigned to a class. This still allows for zero event anomalies to be reported.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if panomaly_status:     \n",
    "    if not len(pan_la_df[pan_la_df['pan_class'] > -1]): panomaly_status = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Calculate the final linkage evaluation metric\n",
    "The final linkage evaluation metric, which denotes the relative \"strength\" or \"importance\" of each linked anomaly pair, is used to decide the True/False verdict for reporting the linkage. This metric, Qpan, is calculated slightly differently depending on the class of the linkage (see below). Future improvements to the calculation of Qpan based on experience could be made in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if panomaly_status: \n",
    "    # Scale factor are used to put the class 1 & 2 Qpan values on a comparable scale as those for class 3 & 4\n",
    "    if (np.isnan(Qp_max)) | (np.isnan(Qg_max)) | (Qp_max == 0.0) | (Qp_max+Qg_max <= 0.0):\n",
    "        Qp_scale_factor = 1.0\n",
    "        Qg_scale_factor = 1.0\n",
    "    else:\n",
    "        Qp_scale_factor = (Qp_max/(Qp_max + Qg_max))\n",
    "        Qg_scale_factor = (Qg_max/Qp_max)\n",
    "        \n",
    "    # Qpan for class 3 & 4 is calculated by combining Qp and Qg using the combine_scores method.\n",
    "    # Qpan for class 1 & 2 is calculated by normalizing the non-zero metric (Qg or Qp, respectively) \n",
    "    # then multiplying by the scale factor.\n",
    "    for nclass in pan_classes:\n",
    "        if nclass == 4: \n",
    "            pan_la_df.at[pan_la_df['pan_class'] == nclass, 'Qpan'] = combine_scores(pan_la_df['Qp'], pan_la_df['Qg'])\n",
    "        if nclass == 3: \n",
    "            pan_la_df.at[pan_la_df['pan_class'] == nclass, 'Qpan'] = combine_scores(pan_la_df['Qp'], pan_la_df['Qg'])\n",
    "        if nclass == 2: \n",
    "            pan_la_df.at[pan_la_df['pan_class'] == nclass, 'Qg'] = -1\n",
    "            pan_la_df.at[pan_la_df['pan_class'] == nclass, 'Qpan'] = normalize_to_max(pan_la_df['Qp'])*Qp_scale_factor\n",
    "        if nclass == 1: \n",
    "            pan_la_df.at[pan_la_df['pan_class'] == nclass, 'Qp'] = -1\n",
    "            pan_la_df.at[pan_la_df['pan_class'] == nclass, 'Qpan'] = normalize_to_max(pan_la_df['Qg'])*Qg_scale_factor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Decide the verdict\n",
    "The Qpan values are sent to verdict_function to decide whether or not a linkage should be surfaced. See the notes above in the verdict_function section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if panomaly_status: \n",
    "    for nclass in [4, 3]:\n",
    "        if nclass == 4: \n",
    "            y1 = pan_la_df[pan_la_df['pan_class'] == nclass].Qpan\n",
    "            y2 = pan_la_df[pan_la_df['pan_class'] == nclass].index\n",
    "            method = 'all'\n",
    "        if nclass == 3: \n",
    "            # this section also applies to class 2 and class 1, but these could be moved into their own sections\n",
    "            y1 = pan_la_df[(pan_la_df['pan_class'] == 3) | (pan_la_df['pan_class'] == 2) | (pan_la_df['pan_class'] == 1)].Qpan\n",
    "            y2 = pan_la_df[(pan_la_df['pan_class'] == 3) | (pan_la_df['pan_class'] == 2) | (pan_la_df['pan_class'] == 1)].index\n",
    "            method = 'limit10'\n",
    "\n",
    "        if len(y1):\n",
    "            for x, i in zip(y1, y2):\n",
    "                pan_Verdict = pan_verdict_function(x, y1, method)\n",
    "                pan_la_df.at[(pan_la_df.index == i), 'Qcrit'] = pan_Verdict[0]\n",
    "                pan_la_df.at[(pan_la_df.index == i), 'Verdict'] = pan_Verdict[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Assemble the final reporting table\n",
    "\n",
    "The following several cells assemble a dataframe ```pan_master_report_df``` containing the linked anomalies with ```True``` verdicts. The anomalies are sorted by class. They have also been combined into groups based on the principle \"if A is linked to B, and B is linked to C, then A is linked to C\". This allows linked anomalies to be reported in groups larger than pairs (although, in some cases, only a pair of anomalies is linked). This table also contains the event names for the anomalous metrics, which shows the event inference relationship between some anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions used to simplify the dataframe construction\n",
    "\n",
    "# Pulls several columns into lists that will be recombined later\n",
    "def extract_series(df, idx):\n",
    "    temp_df = (df.loc[idx, ['Gmod1', 'id_anom1', 'id_metric1', 'metric_name1', 'Gmod2', 'id_anom2', 'id_metric2', 'metric_name2']])\n",
    "    series1 = temp_df['id_anom1'].to_list()+temp_df['id_anom2'].to_list()\n",
    "    series2 = temp_df['id_metric1'].to_list()+temp_df['id_metric2'].to_list()\n",
    "    series3 = temp_df['metric_name1'].to_list()+temp_df['metric_name2'].to_list()\n",
    "    return series1, series2, series3\n",
    "\n",
    "\n",
    "# Creates a dictionary to add to a list of dictionaries used to create the master report dataframe\n",
    "# The fastest way to make a dataframe row-by-row is to construct it from  list of dictionaries, \n",
    "# where each dictionary is one row of the dataframe\n",
    "# https://stackoverflow.com/questions/10715965/add-one-row-to-pandas-dataframe/17496530#17496530\n",
    "def create_series_dict(nclass, class_tags, series1, series2, series3):\n",
    "    return {'pan_class':nclass, 'pan_class_tag':class_tags[nclass], 'id_anom':list(series1), 'id_metric':list(series2), 'metric_name':list(series3)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan_master_report_df = [] # Create placeholder in case panomaly_status = False\n",
    "\n",
    "if panomaly_status: \n",
    "    nclass = 4 # Class being sorted in this cell\n",
    "    # Pull out the class members into a working dataframe\n",
    "    pan_working_df = pan_la_df[pan_la_df['pan_class'] == nclass].sort_values(['Qpan'], ascending=False)\n",
    "\n",
    "    # Create a dictionary of lists for linked anomalies sorted into groups, which\n",
    "    # will be used to create a dataframe that populates the master report dataframe.\n",
    "    pan_series_dict_list = []\n",
    "    for i in sorted(set(pan_working_df['id_anom1'])):\n",
    "        idx = (sorted(set(pan_working_df[(pan_working_df['id_anom1'] == i) & (pan_working_df['id_anom2'] == i) & (pan_working_df['Verdict'] == True)].index.to_list())))\n",
    "        if idx:\n",
    "            pan_series1, pan_series2, pan_series3 = extract_series(pan_working_df, idx)\n",
    "            pan_series1, pan_series2, pan_series3 = zip(*sorted(set(zip(pan_series1, pan_series2, pan_series3))))\n",
    "\n",
    "            pan_series_dict = create_series_dict(nclass, pan_class_tags, pan_series1, pan_series2, pan_series3)\n",
    "            pan_series_dict_list.append(pan_series_dict)\n",
    "\n",
    "    # Create the master report dataframe\n",
    "    if pan_series_dict_list:\n",
    "        pan_series_df = pd.DataFrame(pan_series_dict_list)\n",
    "        pan_master_report_df = pan_series_df.copy()\n",
    "\n",
    "    if VERBOSE: \n",
    "        print('Created dataframe of anomalies/metrics linked to themselves (class = '+str(nclass)+')')\n",
    "        display(pan_master_report_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for existence of pan_master_report_df and create placeholder if it doesn't exist already\n",
    "if len(pan_master_report_df) < 1: pan_master_report_df = [] \n",
    "\n",
    "if panomaly_status: \n",
    "    nclass = 3 # Class being sorted in this cell\n",
    "    # Pull out the class members into a working dataframe\n",
    "    pan_working_df = pan_la_df[pan_la_df['pan_class'] == nclass].sort_values(['Qpan'], ascending=False)\n",
    "\n",
    "    pan_series_dict_list = []\n",
    "    pan_unique_modularity_classes = sorted(set(pan_working_df['Gmod1']))\n",
    "    # Loop over modularity classes, since these define the Graph-based anomaly linkages\n",
    "    for i in pan_unique_modularity_classes:\n",
    "        idx = (sorted(set(pan_working_df[(pan_working_df['Gmod1'] == i) & (pan_working_df['Gmod2'] == i) & (pan_working_df['Verdict'] == True)].index.to_list())))\n",
    "        if idx:\n",
    "            pan_series1, pan_series2, pan_series3 = extract_series(pan_working_df, idx)\n",
    "            pan_series1, pan_series2, pan_series3 = zip(*sorted(set(zip(pan_series1, pan_series2, pan_series3))))\n",
    "\n",
    "            pan_series_dict = create_series_dict(nclass, pan_class_tags, pan_series1, pan_series2, pan_series3)\n",
    "            pan_series_dict_list.append(pan_series_dict)\n",
    "\n",
    "    # Create the master report dataframe if it doesn't exist, otherwise append to it\n",
    "    if pan_series_dict_list:\n",
    "        pan_series_df = pd.DataFrame(pan_series_dict_list)\n",
    "        if len(pan_master_report_df) > 0:\n",
    "            pan_master_report_df = pan_master_report_df.append(pan_series_df, ignore_index=True)\n",
    "        else:\n",
    "            pan_master_report_df = pan_series_df.copy()\n",
    "\n",
    "    if VERBOSE: \n",
    "        print('Appended anomalies/metrics linked by Qp and Qg (class = '+str(nclass)+')')\n",
    "        display(pan_master_report_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for existence of pan_master_report_df and create placeholder if it doesn't exist already\n",
    "if len(pan_master_report_df) < 1: pan_master_report_df = []\n",
    "\n",
    "if panomaly_status: \n",
    "    nclass = 2 # Class being sorted in this cell\n",
    "    # Pull out the class members into a working dataframe\n",
    "    pan_working_df = pan_la_df[pan_la_df['pan_class'] == nclass].sort_values(['Qp'], ascending=False)\n",
    "    # There are a lot of Verdict=False transitions in class = 2, so let's avoid \n",
    "    # iterating over all of them by defining an iteration list of just Verdict=True\n",
    "    pan_working_true_df = pan_la_df[(pan_la_df['pan_class'] == nclass) & (pan_la_df['Verdict'] == True)].sort_values(['Qp'], ascending=False)\n",
    "    pan_working_true_df = pd.unique(pan_working_true_df[['id_anom1', 'id_anom2']].values.ravel('K'))\n",
    "\n",
    "    pan_used_idx = []\n",
    "    pan_series_dict_list = []\n",
    "    for i in pan_working_true_df:\n",
    "        idx0 = (sorted(set(pan_working_df[(pan_working_df['Qp'] > 0) & (pan_working_df['Gmod1'] != pan_working_df['Gmod2']) & (pan_working_df['Verdict'] == True)].index.to_list())))\n",
    "        idx = list(set(idx0) - set(pan_used_idx))\n",
    "        if idx:\n",
    "            if not pan_used_idx:\n",
    "                pan_used_idx = idx.copy()\n",
    "            else:\n",
    "                pan_used_idx = list(set(pan_used_idx.append(idx)))\n",
    "            pan_series1, pan_series2, pan_series3 = extract_series(pan_working_df, idx)\n",
    "            pan_series1, pan_series2, pan_series3 = zip(*sorted(set(zip(pan_series1, pan_series2, pan_series3))))\n",
    "\n",
    "            pan_series_dict = create_series_dict(nclass, pan_class_tags, pan_series1, pan_series2, pan_series3)\n",
    "            pan_series_dict_list.append(pan_series_dict)\n",
    "\n",
    "    # Create the master report dataframe if it doesn't exist, otherwise append to it\n",
    "    if pan_series_dict_list:\n",
    "        pan_series_df = pd.DataFrame(pan_series_dict_list)\n",
    "        if len(pan_master_report_df) > 0:\n",
    "            pan_master_report_df = pan_master_report_df.append(pan_series_df, ignore_index=True)\n",
    "        else:\n",
    "            pan_master_report_df = pan_series_df.copy()\n",
    "\n",
    "    if VERBOSE: \n",
    "        print('Appended anomalies/metrics linked by Qp only (class = '+str(nclass)+')')\n",
    "        display(pan_master_report_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for existence of pan_master_report_df and create placeholder if it doesn't exist already\n",
    "if len(pan_master_report_df) < 1: pan_master_report_df = []\n",
    "\n",
    "if panomaly_status: \n",
    "    nclass = 1 # Class being sorted in this cell\n",
    "    # Pull out the class members into a working dataframe\n",
    "    pan_working_df = pan_la_df[pan_la_df['pan_class'] == nclass].sort_values(['Qg'], ascending=False)\n",
    "\n",
    "    pan_series_dict_list = []\n",
    "    pan_unique_modularity_classes = sorted(set(pan_working_df['Gmod1']))\n",
    "    for i in pan_unique_modularity_classes:\n",
    "        idx = (sorted(set(pan_working_df[(pan_working_df['Gmod1'] == i) & (pan_working_df['Gmod2'] == i) & (pan_working_df['Qp'] <= 0) & (pan_working_df['Verdict'] == True)].index.to_list())))\n",
    "        if idx:\n",
    "            pan_series1, pan_series2, pan_series3 = extract_series(pan_working_df, idx)\n",
    "            pan_series1, pan_series2, pan_series3 = zip(*sorted(set(zip(pan_series1, pan_series2, pan_series3))))\n",
    "\n",
    "            pan_series_dict = create_series_dict(nclass, pan_class_tags, pan_series1, pan_series2, pan_series3)\n",
    "            pan_series_dict_list.append(pan_series_dict)\n",
    "\n",
    "    # Create the master report dataframe if it doesn't exist, otherwise append to it\n",
    "    if pan_series_dict_list:\n",
    "        pan_series_df = pd.DataFrame(pan_series_dict_list)\n",
    "        if len(pan_master_report_df) > 0:\n",
    "            pan_master_report_df = pan_master_report_df.append(pan_series_df, ignore_index=True)\n",
    "        else:\n",
    "            pan_master_report_df = pan_series_df.copy()\n",
    "\n",
    "    if VERBOSE: \n",
    "        print('Appended anomalies/metrics linked by Qg only (class = '+str(nclass)+')')\n",
    "        display(pan_master_report_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check for existence of pan_master_report_df and create placeholder if it doesn't exist already\n",
    "if len(pan_master_report_df) < 1: pan_master_report_df = []\n",
    "\n",
    "if pan_anom_zero_events: \n",
    "    nclass = 0 # Class being sorted in this cell\n",
    "\n",
    "    for item in pan_anom_zero_events:\n",
    "        if len(pan_la_df) > 0:\n",
    "            pan_la_df.loc[(pan_la_df['id_metric1'] == item[1]) & (pan_la_df['id_metric2'] == item[1]) & (pan_la_df['N1'] == 0) & (pan_la_df['N2'] == 0), 'Class'] = 0\n",
    "            pan_la_df.loc[(pan_la_df['id_metric1'] == item[1]) & (pan_la_df['id_metric2'] == item[1]) & (pan_la_df['N1'] == 0) & (pan_la_df['N2'] == 0), 'Qcrit'] = 0\n",
    "            pan_la_df.loc[(pan_la_df['id_metric1'] == item[1]) & (pan_la_df['id_metric2'] == item[1]) & (pan_la_df['N1'] == 0) & (pan_la_df['N2'] == 0), 'Verdict'] = True\n",
    "        \n",
    "        pan_series_dict = create_series_dict(nclass, pan_class_tags, [item[0]], [item[1]], [item[2]])\n",
    "        \n",
    "        # Create the master report dataframe if it doesn't exist, otherwise append to it\n",
    "        pan_series_df = pd.DataFrame(pan_series_dict)\n",
    "        if len(pan_master_report_df) > 0:\n",
    "            pan_master_report_df = pan_master_report_df.append(pan_series_df, ignore_index=True)\n",
    "        else:\n",
    "            pan_master_report_df = pan_series_df.copy()\n",
    "\n",
    "    if VERBOSE: \n",
    "        print('Appended zero event anomalies (class = '+str(nclass)+')')\n",
    "        display(pan_master_report_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is mainly just for troubleshooting - it prints a convenient summary of information at the end of the run.\n",
    "if VERBOSE:\n",
    "    print('panomaly_status =', panomaly_status)\n",
    "    print('pan_anom_zero_events =', pan_anom_zero_events)\n",
    "    if panomaly_status:\n",
    "        print('pan_time_start =', pan_time_start)\n",
    "        if (not pan_anom_zero_events):\n",
    "            print('org, app, users, nodes, anomalies: ', pan_org_id, pan_app_id, pan_nusers, pan_Nnodes, len(pan_anom_ids))\n",
    "        else:\n",
    "            print('org, app, users, nodes, anomalies: ', pan_org_id, pan_app_id, pan_nusers, len(pan_user_metrics_all), len(pan_anom_ids))\n",
    "\n",
    "    display(pan_master_report_df)\n",
    "    display(pan_la_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-panomaly",
   "language": "python",
   "name": "venv-panomaly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
